#!/usr/bin/env python
# coding: utf-8

import streamlit as st
import pandas as pd
import json
import shutil
import os
import time
from langchain_community.document_loaders import JSONLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.documents import Document  
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# **Streamlit UI ì„¤ì •**
st.title("âš½ï¸ ì¶•êµ¬ MBTI ì±—ë´‡ With RAG")

# **1ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ë°›ê¸°**
query = st.text_area("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

if st.button("ğŸ” ë¶„ì„ ì‹œì‘"):

    # **OpenAI ëª¨ë¸ ì´ˆê¸°í™”**
    model = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

    # **2ï¸âƒ£ JSON íŒŒì¼ ë¡œë“œ (ì¶•êµ¬ MBTI ë°ì´í„°)**
    file_path = "./news-sample1.json"
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # **3ï¸âƒ£ JSONì—ì„œ MBTI ê´€ë ¨ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ**
    mbti_keywords = set()
    for entry in data:
        page_content = entry.get("page_content", "")
        words = page_content.split()
        mbti_keywords.update(words)

    # **4ï¸âƒ£ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ MBTI ê´€ë ¨ì¸ì§€ íŒë³„**
    is_mbti_question = any(word in query for word in mbti_keywords)

    # **5ï¸âƒ£ ì±—ë´‡ì˜ `persona` ì„¤ì • (ì¶•êµ¬ MBTI ì „ë¬¸ê°€ì§€ë§Œ ë‹¤ë¥¸ ì§ˆë¬¸ë„ ê°€ëŠ¥)**
    system_message = SystemMessage(
        content="""ë‹¹ì‹ ì€ ì¶•êµ¬ MBTI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
        ì‚¬ìš©ìê°€ ì¶•êµ¬ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ë©´ MBTI ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.  
        ê·¸ëŸ¬ë‚˜ ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì„ í•˜ë©´, ê°€ëŠ¥í•œ í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.  
        """
    )

    if is_mbti_question:
        st.write("ğŸ“Œ **ì¶•êµ¬ MBTI ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...**")

        # **6ï¸âƒ£ MBTI ë¶„ì„ ì§„í–‰**
        title_to_index = {
            entry["metadata"]["title"]: idx
            for idx, entry in enumerate(data)
            if "metadata" in entry and "title" in entry["metadata"]
        }

        documents = [Document(page_content=entry["page_content"], metadata=entry["metadata"]) for entry in data]
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=0)
        docs = text_splitter.split_documents(documents)

        embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")

        DB_PATH = "./chroma_db"
        if os.path.exists(DB_PATH):
            shutil.rmtree(DB_PATH, ignore_errors=True)
        os.makedirs(DB_PATH, exist_ok=True)

        start_time = time.time()

        db = Chroma.from_documents(
            documents=docs,
            embedding=embedding_model,
            persist_directory=DB_PATH
        )

        end_time = time.time()
        st.write(f"ğŸ”¹ Chroma DB ìƒì„± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")

        # **7ï¸âƒ£ MBTI ë¶„ì„ (TF-IDF ìœ ì‚¬ë„ ë¹„êµ)**
        pairs = [("A", "D"), ("P", "T"), ("K", "J"), ("E", "I")]

        vectorizer = TfidfVectorizer()
        page_contents = [doc.page_content for doc in docs] + [query]  
        tfidf_matrix = vectorizer.fit_transform(page_contents)
        query_vector = tfidf_matrix[-1]

        selected_titles = []

        for title1, title2 in pairs:
            if title1 not in title_to_index or title2 not in title_to_index:
                continue
            idx1 = title_to_index[title1]
            idx2 = title_to_index[title2]
            similarity1 = cosine_similarity(query_vector, tfidf_matrix[idx1])[0][0]
            similarity2 = cosine_similarity(query_vector, tfidf_matrix[idx2])[0][0]
            chosen_title = title1 if similarity1 > similarity2 else title2
            selected_titles.append(chosen_title)

        mbti_result = "".join(selected_titles)
        st.write(f"ğŸ“Œ MBTI ê²°ê³¼: **{mbti_result}**")

        # **ğŸ† ì„ ìˆ˜ ì¶”ì²œ**
        processed_file_path = './player.xlsx'
        processed_data = pd.read_excel(processed_file_path)
        filtered_data = processed_data[processed_data['MBTI ì½”ë“œ'] == mbti_result]

        if filtered_data.empty:
            st.warning("âš ï¸ í•´ë‹¹ MBTI ì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ” ì„ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            filtered_data['ê²½ê¸°'] = pd.to_numeric(filtered_data['ê²½ê¸°'], errors='coerce')
            top_3_players = filtered_data.nlargest(3, 'ê²½ê¸°')[['ì„ ìˆ˜', 'íŒ€', 'ê²½ê¸°']]
            top_3_players_str = top_3_players.to_string(index=False)
            st.write("ğŸ† ì¶”ì²œ ì„ ìˆ˜:")
            st.dataframe(top_3_players)

            # **ğŸ”Ÿ MBTI ì§ˆë¬¸ì¼ ë•Œ íŠ¹ì • í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€**
            chat_template1 = ChatPromptTemplate.from_messages(
                [
                    SystemMessage(
                        content=f"""ë‹¹ì‹ ì€ ì¶•êµ¬ ì „ë¬¸ê°€ì´ë©´ì„œ ì‹¬ë¦¬í–‰ë™ì „ë¬¸ê°€ì•¼.
                        ì‚¬ìš©ìê°€ ë„ˆì—ê²Œ ë§í•˜ëŠ” ì„±í–¥ì„ ë°”íƒ•ìœ¼ë¡œ ìš°ë¦¬ê°€ ë§Œë“  ì¶•êµ¬ MBTIë¥¼ ë¶„ì„í•˜ê³ , ì‚¬ìš©ìì—ê²Œ ê·¸ ê²°ê³¼ë¥¼ ì•Œë ¤ì¤˜.
                        A(attack) 
                        D(defence) 
                        T(team)
                        P(personal)
                        K(key) 
                        J(joker)
                        E(extroversion)
                        I(Introverted)


                        ì´ ìˆœì„œëŒ€ë¡œ í•´ë‹¹ë˜ëŠ” ì˜ì–´ì— ë”°ë¼ í•´ë‹¹ë˜ëŠ” 4ê°œë¥¼ ì„¤ëª…í•´ì¤˜
                        
                        ê¼­ ì¶•êµ¬MBTI {mbti_result} ì‚¬ìš©ìì—ê²Œ 4ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ì œê³µí•´ì•¼ í•˜ê³ ,  
                        ì •ë³´ê°€ ë¶€ì¡±í•´ë„ ì¼ë‹¨ ì‚¬ìš©ìê°€ ì œê³µí•œ ë°ì´í„°ë¡œ ì•Œë ¤ì¤˜!
                        ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª…ì„ 3ì¤„ ì´ìƒìœ¼ë¡œ ê¸¸ê³  ìì„¸í•˜ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜.
                        ë§ˆì§€ë§‰ì—ëŠ” ì‚¬ìš©ìì˜ MBTI {mbti_result} ê²°ê³¼ì™€ ê°™ì€ ì¶•êµ¬ ì„ ìˆ˜ 3ëª…ì„ ì¶”ì²œí•´ì¤˜.

                        ì•„ë˜ëŠ” 2023~2024 ì‹œì¦Œ EPLë¦¬ê·¸ì—ì„œ ë›°ì—ˆë˜ ë¹„ìŠ·í•œ ìœ í˜•ì˜ ì„ ìˆ˜ ë°ì´í„°ì•¼:
                        {top_3_players_str}
                        ë°‘ì— ê° ì„ ìˆ˜ì— ëŒ€í•œ ì†Œì†íŒ€, í¬ì§€ì…˜, í”Œë ˆì´ìŠ¤íƒ€ì¼, ë‚˜ì´, êµ­ì , í‰ê°€ ë“±ë“± í•´ë‹¹ ì„ ìˆ˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ë§¤ìš° êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì¤˜
                        <ì˜ˆì‹œ>
                        ***2023~2024 ì‹œì¦Œ EPLë¦¬ê·¸ì—ì„œ ë›°ì—ˆë˜ ë¹„ìŠ·í•œ ìœ í˜•ì˜ ì„ ìˆ˜ë¥¼ ì¶”ì²œí•˜ê² ìŠµë‹ˆë‹¤***
                        ì†Œì†íŒ€:
                        ë‚˜ì´:
                        êµ­ì :
                        í¬ì§€ì…˜:
                        í‰ê°€:
                        """
                    ),
                    HumanMessage(content=query)
                ]
            )

            messages1 = chat_template1.format_messages(text=query)
            st.write("ğŸ“Š **MBTI ë¶„ì„ ê²°ê³¼**")

            # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ placeholder ìƒì„±
            output_placeholder = st.empty()

            output = ""
            for chunk in model.stream(messages1):
                output += chunk.content
                output_placeholder.write(output)

    else:
        # **MBTI ê´€ë ¨ì´ ì•„ë‹Œ ì§ˆë¬¸ì´ë©´ OpenAIë¥¼ ì´ìš©í•´ ì¼ë°˜ ì‘ë‹µ ì œê³µ**
        st.write("ğŸ’¡ ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤. OpenAIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘...")
        messages = [
            system_message,  # âœ… ì„¤ì •ëœ ì—­í• ì„ ë°˜ì˜
            HumanMessage(content=query)
        ]
        response = model.invoke(messages)
        st.write("ğŸ“– **OpenAI ì‘ë‹µ:**")
        st.write(response.content)
